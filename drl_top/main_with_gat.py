# -*- coding: utf-8 -*-
"""
MATD3è®­ç»ƒè„šæœ¬ - åŒ…å«GATç«¯åˆ°ç«¯è®­ç»ƒ
åŸºäºmain_no_gat.pyï¼Œæ·»åŠ GATè”åˆè®­ç»ƒåŠŸèƒ½
"""
import sys
import os

# è·å–å½“å‰æ–‡ä»¶çš„çˆ¶ç›®å½•ï¼ˆmpe_uavç›®å½•ï¼‰
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)  # mpe_uavç›®å½•
sys.path.append(parent_dir)

import cv2
import random
import torch
import numpy as np
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
import imageio
import time

# å¯¼å…¥æœ¬åœ°æ¨¡å—
from uav_top_env.uav_env_top import UAVEnv
from matd3_no_gat import MATD3, ReplayBuffer
from config import CONFIG

# è·å–å½“å‰æ–‡ä»¶ç›®å½•è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
model_dir = os.path.join(current_dir, './output_with_gat/models/test1')  # æ¨¡å‹ä¿å­˜æ–‡ä»¶å¤¹
video_dir = os.path.join(current_dir, './output_with_gat/videos/test1')  # è§†é¢‘ä¿å­˜æ–‡ä»¶å¤¹
runs_dir = os.path.join(current_dir, './output_with_gat/runs/test1')  # TensorBoard æ—¥å¿—æ–‡ä»¶å¤¹

FRAME_SAVE_INTERVAL = 10  # å‡å°‘è§†é¢‘ä¿å­˜é¢‘ç‡ï¼Œæé«˜è®­ç»ƒé€Ÿåº¦
final_times = 20  # å‡å°‘æœ€åä¿å­˜çš„è§†é¢‘æ•°é‡

# è‡ªåŠ¨åˆ›å»º models å’Œ videos æ–‡ä»¶å¤¹
os.makedirs(model_dir, exist_ok=True)
os.makedirs(video_dir, exist_ok=True)
os.makedirs(runs_dir, exist_ok=True)

def main():
    # è®¾ç½®æ€§èƒ½ä¼˜åŒ–å‚æ•°
    torch.backends.cudnn.benchmark = True
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.allow_tf32 = True

    writer = SummaryWriter(log_dir=runs_dir)  # TensorBoard æ—¥å¿—æ–‡ä»¶å¤¹
    render_mode = CONFIG["render_mode"]
    num_episodes = CONFIG["num_episodes"]
    max_steps_per_episode = CONFIG["max_steps_per_episode"]
    initial_random_steps = CONFIG["initial_random_steps"]  # åˆå§‹éšæœºæ­¥éª¤

    # è®¾ç½®éšæœºç§å­
    seed = random.randint(0, 1000)  # éšæœºç§å­
    np.random.seed(seed)
    torch.manual_seed(seed)
    random.seed(seed)  # ä¹Ÿè®¾ç½®Pythonçš„éšæœºç§å­

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    # åˆå§‹åŒ–ç¯å¢ƒ - é‡è¦ï¼šå¯ç”¨GATè®­ç»ƒæ¨¡å¼
    env = UAVEnv(
        render_mode=render_mode,
        experiment_type='probabilistic',  # 'normal' æˆ– 'probabilistic'
        num_agents=8,
        num_targets=12,
        min_active_agents=3,
        max_active_agents=8
    )

    # å…³é”®ï¼šè®¾ç½®ç¯å¢ƒä¸ºè®­ç»ƒæ¨¡å¼ï¼Œè¿™æ ·GATæ¢¯åº¦ä¸ä¼šè¢«detach
    env.training = True
    print("ğŸ”¥ GATè®­ç»ƒæ¨¡å¼å·²å¯ç”¨")

    obs, _ = env.reset(seed=seed)
    # è·å–æ™ºèƒ½ä½“åˆ—è¡¨
    agents = env.agents

    # è·å–è§‚æµ‹å’ŒåŠ¨ä½œç©ºé—´ç»´åº¦
    obs_dim = env.get_observation_space(agents[0]).shape[0]
    action_dim = env.get_action_space(agents[0]).shape[0]

    # åˆ›å»ºè§‚æµ‹å’ŒåŠ¨ä½œç»´åº¦çš„å­—å…¸
    obs_dims = {agent: obs_dim for agent in agents}
    action_dims = {agent: action_dim for agent in agents}

    # åˆå§‹åŒ– MATD3
    model_path = os.path.join(model_dir, "matd3_gat_model_episode_4000.pth")
    matd3 = MATD3(
        agents=agents,
        obs_dims=obs_dims,
        action_dims=action_dims,
        device=device,
        actor_lr=CONFIG["actor_lr"],
        critic_lr=CONFIG["critic_lr"],
        gamma=CONFIG["gamma"],
        tau=CONFIG["tau"],
        policy_noise=CONFIG.get("noise_std", 0.2),
        noise_clip=CONFIG.get("noise_clip", 0.5),
        policy_delay=CONFIG.get("policy_delay", 2)
    )

    # å…³é”®ï¼šè·å–GATå‚æ•°å¹¶æ·»åŠ åˆ°ä¼˜åŒ–å™¨
    gat_params = list(env.get_gat_parameters())
    print(f"GATå‚æ•°æ•°é‡: {sum(p.numel() for p in gat_params)}")

    # ä¸ºæ¯ä¸ªæ™ºèƒ½ä½“çš„ä¼˜åŒ–å™¨æ·»åŠ GATå‚æ•°
    print("æ­£åœ¨é‡æ–°é…ç½®ä¼˜åŒ–å™¨ä»¥åŒ…å«GATå‚æ•°...")
    for agent in agents:
        # è·å–ç°æœ‰çš„ç­–ç•¥ç½‘ç»œå‚æ•°
        actor_params = list(matd3.actors[agent].parameters())
        critic_params = list(matd3.critics_1[agent].parameters()) + list(matd3.critics_2[agent].parameters())

        # é‡æ–°åˆ›å»ºä¼˜åŒ–å™¨ï¼ŒåŒ…å«GATå‚æ•°
        matd3.actor_optimizers[agent] = torch.optim.Adam(
            actor_params + gat_params,
            lr=CONFIG["actor_lr"]
        )
        matd3.critic_optimizers[agent] = torch.optim.Adam(
            critic_params + gat_params,
            lr=CONFIG["critic_lr"]
        )
    print("âœ… ä¼˜åŒ–å™¨é…ç½®å®Œæˆï¼ŒGATå°†ä¸ç­–ç•¥ç½‘ç»œè”åˆè®­ç»ƒ")

    # åˆå§‹åŒ–æˆ–åŠ è½½æ¨¡å‹
    if os.path.exists(model_path):
        print("åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹...")
        try:
            matd3.load(model_path)
            # å°è¯•åŠ è½½GATå‚æ•°
            gat_path = model_path.replace('.pth', '_gat.pth')
            if os.path.exists(gat_path):
                env.load_gat_model(gat_path)
                print("æ¨¡å‹å’ŒGATåŠ è½½å®Œæˆã€‚")
            else:
                print("æ¨¡å‹åŠ è½½å®Œæˆï¼ŒGATä½¿ç”¨åˆå§‹å‚æ•°ã€‚")
        except Exception as e:
            print(f"åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {e}")
            print("åˆå§‹åŒ–æ–°æ¨¡å‹ã€‚")

    # åˆå§‹åŒ– ReplayBuffer
    replay_buffer = ReplayBuffer(
        buffer_size=CONFIG["buffer_size"],
        batch_size=CONFIG["batch_size"],
        device=device
    )

    # åˆå§‹åŒ–å™ªå£°
    noise_std = CONFIG.get("noise_std", 0.1)
    noise_decay_rate = CONFIG.get("noise_decay_rate", 0.995)

    total_rewards = []
    actor_losses = []
    critic_losses = []
    training_start_time = time.time()

    # åˆå§‹å¡«å……ç»éªŒå›æ”¾ç¼“å†²åŒº
    print(f"åˆå§‹éšæœºé‡‡æ · {initial_random_steps} æ­¥...")
    obs, _ = env.reset()
    for step in tqdm(range(initial_random_steps)):
        # å®Œå…¨éšæœºåŠ¨ä½œ
        actions = {agent: np.random.uniform(-1, 1, env.get_action_space(agent).shape) for agent in agents if agent in obs}
        next_obs, rewards, dones, truncated, infos = env.step(actions)

        # å°†ç»éªŒæ·»åŠ åˆ° Replay Buffer
        all_agents = set(agents) | set(obs.keys()) | set(next_obs.keys())
        obs_filled = {agent: obs.get(agent, np.zeros(obs_dim)) for agent in all_agents}
        actions_filled = {agent: actions.get(agent, np.zeros(action_dim)) for agent in all_agents}
        rewards_filled = {agent: rewards.get(agent, 0.0) for agent in all_agents}
        next_obs_filled = {agent: next_obs.get(agent, np.zeros(obs_dim)) for agent in all_agents}
        dones_filled = {agent: dones.get(agent, True) for agent in all_agents}

        replay_buffer.add(obs_filled, actions_filled, rewards_filled, next_obs_filled, dones_filled)

        obs = next_obs
        if all([dones.get(agent, True) for agent in agents]):
            obs, _ = env.reset()

    print("ğŸ”¥ å¼€å§‹GAT+MATD3è”åˆè®­ç»ƒ...")
    print(f"GATå‚æ•°å°†ä¸ç­–ç•¥ç½‘ç»œä¸€èµ·æ›´æ–°")

    # è®­ç»ƒå¾ªç¯ - å®Œå…¨åŸºäºmain_no_gat.pyçš„ç»“æ„
    for episode in tqdm(range(num_episodes), desc="GATè®­ç»ƒè¿›åº¦"):
        # éšæœºç§å­
        episode_seed = random.randint(0, 1000)  # æ¯ä¸€è½®éƒ½è®¾ç½®ä¸€ä¸ªæ–°çš„éšæœºç§å­
        # æ¯éš” FRAME_SAVE_INTERVAL è½®ä¿å­˜ä¸€æ¬¡è§†é¢‘ï¼Œè¿˜æœ‰æœ€å final_times è½®ä¿å­˜è§†é¢‘
        record_video = (episode % FRAME_SAVE_INTERVAL == 0) or (episode >= num_episodes - final_times)
        obs, _ = env.reset(seed=episode_seed)
        episode_reward = 0
        frames = []
        max_coverage_rate = 0  # æ¯ä¸€è½®é‡ç½®æœ€å¤§è¦†ç›–ç‡

        # åŠ¨æ€è°ƒæ•´å™ªå£°
        current_noise = noise_std * (noise_decay_rate ** episode)

        step_count = 0
        episode_start_time = time.time()

        for step in range(max_steps_per_episode):
            step_count += 1

            # ä½¿ç”¨ MATD3 çš„ select_action æ–¹æ³•é€‰æ‹©åŠ¨ä½œ
            actions = matd3.select_action(obs, noise=current_noise)

            next_obs, rewards, dones, truncated, infos = env.step(actions)
            episode_reward += sum(rewards.values())

            # å°†ç»éªŒæ·»åŠ åˆ° Replay Buffer
            all_agents = set(agents) | set(obs.keys()) | set(next_obs.keys())
            obs_filled = {agent: obs.get(agent, np.zeros(obs_dim)) for agent in all_agents}
            actions_filled = {agent: actions.get(agent, np.zeros(action_dim)) for agent in all_agents}
            rewards_filled = {agent: rewards.get(agent, 0.0) for agent in all_agents}
            next_obs_filled = {agent: next_obs.get(agent, np.zeros(obs_dim)) for agent in all_agents}
            dones_filled = {agent: dones.get(agent, True) for agent in all_agents}

            try:
                replay_buffer.add(obs_filled, actions_filled, rewards_filled, next_obs_filled, dones_filled)
            except Exception as e:
                print(f"æ·»åŠ åˆ°ç»éªŒå›æ”¾ç¼“å†²åŒºæ—¶å‡ºé”™: {e}")
                continue

            # å½“ç»éªŒå›æ”¾ç¼“å†²åŒºæœ‰è¶³å¤Ÿçš„æ ·æœ¬æ—¶å¼€å§‹è®­ç»ƒ
            if len(replay_buffer) > CONFIG["batch_size"]:
                # æ›´æ–° MATD3 ç½‘ç»œï¼ˆç°åœ¨åŒ…å«GATå‚æ•°ï¼‰
                loss_info = matd3.train(replay_buffer)
                actor_loss = loss_info['actor_loss']
                critic_loss = loss_info['critic_loss']

                actor_losses.append(actor_loss)
                critic_losses.append(critic_loss)

            # å¦‚æœæ‰€æœ‰æ™ºèƒ½ä½“éƒ½å®Œæˆï¼Œåˆ™æå‰ç»“æŸ
            if all([dones.get(agent, True) for agent in agents]):
                break

            obs = next_obs

            # ä¿å­˜å½“å‰å¸§åˆ°è§†é¢‘ï¼ˆæ ¹æ® record_videoï¼‰
            if record_video and step % 2 == 0:  # æ¯éš”2æ­¥ä¿å­˜ä¸€å¸§ï¼Œå‡å°‘å†…å­˜ä½¿ç”¨
                frame = env.render()
                frame = cv2.resize(frame, (704, 704))
                frames.append(frame)

        # è®¡ç®—å¹¶è®°å½•è¦†ç›–ç‡
        coverage_rate, is_fully_connected, max_coverage_rate, unconnected_uav = env.calculate_coverage_complete()
        max_coverage_rate = max(coverage_rate, max_coverage_rate)

        # å°†è¦†ç›–ç‡è®°å½•åˆ° TensorBoard
        writer.add_scalar('Coverage Rate', coverage_rate, episode)      # æ­£å¸¸çš„è¦†ç›–ç‡
        writer.add_scalar('Max Coverage Rate', max_coverage_rate, episode)  # æœ€å¤§çš„è¦†ç›–ç‡
        writer.add_scalar('Unconnected Uav', unconnected_uav, episode)  # æœªè¿æ¥çš„æ— äººæœºæ•°é‡
        writer.add_scalar('Noise Level', current_noise, episode)        # è®°å½•å™ªå£°æ°´å¹³

        total_rewards.append(episode_reward)
        episode_time = time.time() - episode_start_time
        total_time = time.time() - training_start_time

        # åªåœ¨ç‰¹å®šé—´éš”æ‰“å°è¯¦ç»†ä¿¡æ¯ï¼Œå‡å°‘è¾“å‡º
        if episode % 10 == 0 or episode < 10:
            print(f"\nå›åˆ {episode + 1}/{num_episodes} å®Œæˆ (ç”¨æ—¶: {episode_time:.2f}ç§’, æ€»æ—¶é—´: {total_time/60:.2f}åˆ†é’Ÿ):")
            print(f"æ€»å¥–åŠ±: {episode_reward:.2f}")
            print(f"æœ€å¤§è¦†ç›–ç‡: {max_coverage_rate*100:.2f}%")
            print(f"å½“å‰è¦†ç›–ç‡: {coverage_rate * 100:.2f}%")
            print(f"æ­¥éª¤æ•°: {step_count}, å™ªå£°æ°´å¹³: {current_noise:.4f}")
            if actor_losses and critic_losses:
                print(f"ActoræŸå¤±: {actor_losses[-1]:.4f}, CriticæŸå¤±: {critic_losses[-1]:.4f}")
                print(f"ğŸ”¥ GATå‚æ•°æ­£åœ¨è”åˆè®­ç»ƒä¸­...")

        # TensorBoard å¯è§†åŒ–
        writer.add_scalar('Total Reward', episode_reward, episode)
        writer.add_scalar('Steps Per Episode', step_count, episode)
        writer.add_scalar('Episode Time', episode_time, episode)
        if actor_losses and critic_losses:
            writer.add_scalar('Actor Loss', actor_losses[-1], episode)
            writer.add_scalar('Critic Loss', critic_losses[-1], episode)

        # æ¯éš”500è½®ä¿å­˜ä¸€æ¬¡æ¨¡å‹ï¼Œå‡å°‘IOæ“ä½œ
        if (episode + 1) % 500 == 0:
            intermediate_model_path = os.path.join(model_dir, f"matd3_gat_model_episode_{episode + 1}.pth")
            intermediate_gat_path = os.path.join(model_dir, f"matd3_gat_model_episode_{episode + 1}_gat.pth")
            try:
                matd3.save(intermediate_model_path)
                env.save_gat_model(intermediate_gat_path)
                print(f"æ¨¡å‹å’ŒGATå·²ä¿å­˜åˆ° {intermediate_model_path}")
            except Exception as e:
                print(f"ä¿å­˜æ¨¡å‹æ—¶å‡ºé”™: {e}")

        # æ¯éš”è§†é¢‘ä¿å­˜é—´éš”ä¿å­˜ä¸€æ¬¡è§†é¢‘
        if record_video and frames:
            try:
                video_path = os.path.join(video_dir, f"{episode + 1}_{int(total_rewards[episode])}_{max_coverage_rate* 100:.2f}%_{coverage_rate * 100:.2f}%.mp4")
                with imageio.get_writer(video_path, fps=10) as video:
                    for frame in frames:
                        video.append_data(frame)
                print(f"è§†é¢‘å·²ä¿å­˜åˆ° {video_path}")
            except Exception as e:
                print(f"ä¿å­˜è§†é¢‘æ—¶å‡ºé”™: {e}")

    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    model_save_path = os.path.join(model_dir, f"matd3_gat_model_episode_{num_episodes}.pth")
    gat_save_path = os.path.join(model_dir, f"matd3_gat_model_episode_{num_episodes}_gat.pth")
    matd3.save(model_save_path)
    env.save_gat_model(gat_save_path)
    print(f"æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜åˆ° {model_save_path}")
    print(f"æœ€ç»ˆGATå·²ä¿å­˜åˆ° {gat_save_path}")

    # æ‰“å°æ€»è®­ç»ƒæ—¶é—´
    total_training_time = time.time() - training_start_time
    print(f"æ€»è®­ç»ƒæ—¶é—´: {total_training_time/60:.2f}åˆ†é’Ÿ ({total_training_time/3600:.2f}å°æ—¶)")
    print("ğŸ‰ GAT+MATD3è”åˆè®­ç»ƒå®Œæˆï¼")

    writer.close()
    env.close()

if __name__ == "__main__":
    main()
