# -*- coding: utf-8 -*-
"""
ä½¿ç”¨ç®€åŒ–ç¯å¢ƒçš„MATD3è®­ç»ƒè„šæœ¬
åŸºäºmain_no_gat.pyï¼Œé€‚é…uav_env_clean.py
"""

import sys
import os

# è·å–å½“å‰æ–‡ä»¶çš„çˆ¶ç›®å½•ï¼ˆmpe_uavç›®å½•ï¼‰
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)  # mpe_uavç›®å½•
sys.path.append(parent_dir)

import cv2
import torch
import numpy as np
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm
import time
import imageio  # ç®€åŒ–è§†é¢‘ä¿å­˜

# å¯¼å…¥ç®€åŒ–ç¯å¢ƒå’ŒMATD3
import importlib.util
uav_env_path = os.path.join(parent_dir, 'uav_top_env', 'uav_env_clean.py')
spec = importlib.util.spec_from_file_location("uav_env_clean", uav_env_path)
uav_env_module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(uav_env_module)
UAVEnv = uav_env_module.UAVEnv

from matd3_no_gat import MATD3, ReplayBuffer
from config import CONFIG

# è·å–å½“å‰æ–‡ä»¶ç›®å½•è·¯å¾„
# ç®€åŒ–è·¯å¾„è®¾ç½®ï¼Œä¿®å¤TensorBoardè·¯å¾„é—®é¢˜
model_dir = './output_clean_env/models/test1'  # ç®€åŒ–è·¯å¾„
video_dir = './output_clean_env/videos/test1'  # ç®€åŒ–è·¯å¾„
runs_dir = './runs/test1'  # TensorBoardä¸“ç”¨ç®€åŒ–è·¯å¾„

# åˆ›å»ºç›®å½•
os.makedirs(model_dir, exist_ok=True)
os.makedirs(video_dir, exist_ok=True)
os.makedirs(runs_dir, exist_ok=True)

def setup_cuda():
    """è®¾ç½®CUDAä¼˜åŒ–"""
    if torch.cuda.is_available():
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False
        print(f"ğŸš€ ä½¿ç”¨GPU: {torch.cuda.get_device_name()}")
    else:
        print("âš ï¸  ä½¿ç”¨CPUè®­ç»ƒ")

def setup_seeds(seed=42):
    """è®¾ç½®éšæœºç§å­"""
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)

def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    print("ğŸš€ å¼€å§‹ä½¿ç”¨ç®€åŒ–ç¯å¢ƒè®­ç»ƒMATD3")
    
    # è®¾ç½®ä¼˜åŒ–å’Œç§å­
    setup_cuda()
    setup_seeds()
    
    # è®­ç»ƒå‚æ•°
    num_episodes = CONFIG["num_episodes"]
    max_steps = CONFIG["max_steps"]
    initial_random_steps = CONFIG["initial_random_steps"]
    render_mode = None  # 'human' æˆ– None

    # é€Ÿåº¦ä¼˜åŒ–å‚æ•°
    train_frequency = CONFIG.get("train_frequency", 3)  # æ¯3æ­¥è®­ç»ƒä¸€æ¬¡
    log_interval = CONFIG.get("log_interval", 10)       # æ¯10æ­¥è®°å½•ä¸€æ¬¡æ—¥å¿—
    
    # åˆ›å»ºç®€åŒ–ç¯å¢ƒ
    env = UAVEnv(
        render_mode=render_mode,
        experiment_type='probabilistic',  # ä½¿ç”¨æ¦‚ç‡é©±åŠ¨æ‹“æ‰‘å˜åŒ–
        num_agents=5,
        num_targets=10,
        max_steps=max_steps,
        min_active_agents=4,
        max_active_agents=6
    )
    
    print(f"âœ… ç¯å¢ƒåˆ›å»ºæˆåŠŸ")
    print(f"ç¯å¢ƒç±»å‹: {env.__class__.__name__}")
    print(f"å®éªŒæ¨¡å¼: {env.experiment_type}")
    print(f"UAVæ•°é‡: {env.num_agents}")
    print(f"ç›®æ ‡æ•°é‡: {env.num_targets}")
    
    # è·å–ç¯å¢ƒä¿¡æ¯
    obs, _ = env.reset()
    agents = env.agents
    
    obs_dim = env.get_observation_space(agents[0]).shape[0]
    action_dim = env.get_action_space(agents[0]).shape[0]
    
    print(f"è§‚å¯Ÿç»´åº¦: {obs_dim}")
    print(f"åŠ¨ä½œç»´åº¦: {action_dim}")
    print(f"æ™ºèƒ½ä½“æ•°é‡: {len(agents)}")
    
    # åˆ›å»ºMATD3ç®—æ³•
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    obs_dims = {agent: obs_dim for agent in agents}
    action_dims = {agent: action_dim for agent in agents}
    
    matd3 = MATD3(
        agents=agents,
        obs_dims=obs_dims,
        action_dims=action_dims,
        device=device,
        actor_lr=CONFIG["actor_lr"],
        critic_lr=CONFIG["critic_lr"]
    )
    
    # åˆ›å»ºç»éªŒå›æ”¾
    replay_buffer = ReplayBuffer(
        buffer_size=CONFIG["buffer_size"],
        batch_size=CONFIG["batch_size"],
        device=device
    )
    
    # åˆ›å»ºTensorBoardè®°å½•å™¨
    writer = SummaryWriter(runs_dir)

    print(f"ğŸ“Š TensorBoardæ—¥å¿—: {runs_dir}")
    print(f"ğŸ’¾ æ¨¡å‹ä¿å­˜ç›®å½•: {model_dir}")
    print(f"ğŸ“¹ è§†é¢‘ä¿å­˜ç›®å½•: {video_dir}")
    
    # åˆå§‹éšæœºé‡‡æ ·
    print(f"ğŸ² å¼€å§‹åˆå§‹éšæœºé‡‡æ · ({initial_random_steps} æ­¥)...")
    obs, _ = env.reset()
    
    for step in tqdm(range(initial_random_steps)):
        # å®Œå…¨éšæœºåŠ¨ä½œ
        actions = {agent: np.random.uniform(-1, 1, env.get_action_space(agent).shape) 
                  for agent in agents if agent in obs}
        next_obs, rewards, dones, truncated, infos = env.step(actions)
        
        # å°†ç»éªŒæ·»åŠ åˆ° Replay Buffer
        all_agents = set(agents) | set(obs.keys()) | set(next_obs.keys())
        obs_filled = {agent: obs.get(agent, np.zeros(obs_dim)) for agent in all_agents}
        actions_filled = {agent: actions.get(agent, np.zeros(action_dim)) for agent in all_agents}
        rewards_filled = {agent: rewards.get(agent, 0.0) for agent in all_agents}
        next_obs_filled = {agent: next_obs.get(agent, np.zeros(obs_dim)) for agent in all_agents}
        dones_filled = {agent: dones.get(agent, True) for agent in all_agents}
        
        replay_buffer.add(obs_filled, actions_filled, rewards_filled, next_obs_filled, dones_filled)
        obs = next_obs
        
        # å¦‚æœepisodeç»“æŸï¼Œé‡ç½®ç¯å¢ƒ
        if any(dones.values()):
            obs, _ = env.reset()
    
    print(f"âœ… åˆå§‹é‡‡æ ·å®Œæˆï¼Œç¼“å†²åŒºå¤§å°: {len(replay_buffer)}")
    
    # å¼€å§‹è®­ç»ƒ
    print(f"ğŸ¯ å¼€å§‹è®­ç»ƒ ({num_episodes} episodes)...")
    
    # è®­ç»ƒç»Ÿè®¡
    episode_rewards = []
    episode_coverages = []
    max_coverage_rate = 0.0
    
    # å™ªå£°å‚æ•°
    noise_std = CONFIG["noise_std"]
    noise_decay = CONFIG["noise_decay"]
    min_noise = CONFIG["min_noise"]
    
    for episode in tqdm(range(num_episodes), desc="è®­ç»ƒè¿›åº¦"):
        obs, _ = env.reset()
        episode_reward = 0
        episode_coverage_history = []
        
        # å½“å‰å™ªå£°
        current_noise = max(min_noise, noise_std * (noise_decay ** episode))
        
        # è§†é¢‘å½•åˆ¶ï¼ˆæ¯50ä¸ªepisodeå½•åˆ¶ä¸€æ¬¡ï¼Œæé«˜å½•åˆ¶é¢‘ç‡ï¼‰
        frames = []
        record_video = (episode % 50 == 0) and render_mode is None
        
        for step in range(max_steps):
            # ä½¿ç”¨ MATD3 çš„ select_action æ–¹æ³•é€‰æ‹©åŠ¨ä½œ
            actions = matd3.select_action(obs, noise=current_noise)

            next_obs, rewards, dones, truncated, infos = env.step(actions)
            episode_reward += sum(rewards.values())

            # å°†ç»éªŒæ·»åŠ åˆ° Replay Buffer
            all_agents = set(agents) | set(obs.keys()) | set(next_obs.keys())
            obs_filled = {agent: obs.get(agent, np.zeros(obs_dim)) for agent in all_agents}
            actions_filled = {agent: actions.get(agent, np.zeros(action_dim)) for agent in all_agents}
            rewards_filled = {agent: rewards.get(agent, 0.0) for agent in all_agents}
            next_obs_filled = {agent: next_obs.get(agent, np.zeros(obs_dim)) for agent in all_agents}
            dones_filled = {agent: dones.get(agent, True) for agent in all_agents}

            replay_buffer.add(obs_filled, actions_filled, rewards_filled, next_obs_filled, dones_filled)

            # è®­ç»ƒç½‘ç»œï¼ˆä¼˜åŒ–è®­ç»ƒé¢‘ç‡ï¼‰
            if len(replay_buffer) > CONFIG["batch_size"] and step % train_frequency == 0:
                # æ‰¹é‡è®­ç»ƒæé«˜æ•ˆç‡
                loss_info = None
                for _ in range(2):  # æ¯æ¬¡è§¦å‘è®­ç»ƒ2è½®
                    loss_info = matd3.train(replay_buffer)

                # è®°å½•æŸå¤±åˆ°TensorBoardï¼ˆå‡å°‘å†™å…¥é¢‘ç‡ï¼‰
                if loss_info and step % log_interval == 0:
                    writer.add_scalar('Loss/Actor', loss_info['actor_loss'], episode * max_steps + step)
                    writer.add_scalar('Loss/Critic', loss_info['critic_loss'], episode * max_steps + step)

            obs = next_obs

            # å½•åˆ¶è§†é¢‘å¸§
            if record_video:
                try:
                    # ä¸´æ—¶è®¾ç½®render_modeä¸ºrgb_array
                    original_mode = env.render_mode
                    env.render_mode = 'rgb_array'
                    frame = env.render()
                    env.render_mode = original_mode

                    if frame is not None and len(frame.shape) == 3:
                        # ç¡®ä¿å¸§æ ¼å¼æ­£ç¡®
                        if frame.shape[2] == 3:  # RGBæ ¼å¼
                            frames.append(frame)
                        else:
                            print(f"âš ï¸  å¸§æ ¼å¼é”™è¯¯: {frame.shape}")
                    elif frame is None:
                        print(f"âš ï¸  æ¸²æŸ“è¿”å›None (step {step})")
                except Exception as e:
                    print(f"âŒ æ¸²æŸ“å‡ºé”™ (step {step}): {e}")

        # è®¡ç®—å¹¶è®°å½•è¦†ç›–ç‡
        final_coverage_rate, is_fully_connected, episode_max_coverage, unconnected_uav = env.calculate_coverage_complete()
        max_coverage_rate = max(final_coverage_rate, max_coverage_rate)

        # è·å–episodeä¿¡æ¯
        episode_type = env.episode_plan['type']
        trigger_step = env.episode_plan['trigger_step']
        executed = env.episode_plan['executed']

        # æ‰“å°è¯¦ç»†çš„episodeä¿¡æ¯
        print(f"Episode {episode:4d}: ç±»å‹={episode_type:8s} | "
              f"å¥–åŠ±={episode_reward:7.2f} | "
              f"æœ€ç»ˆè¦†ç›–ç‡={final_coverage_rate:.3f} | "
              f"æœ€å¤§è¦†ç›–ç‡={episode_max_coverage:.3f} | "
              f"æ´»è·ƒUAV={len(env.active_agents)}/{env.num_agents} | "
              f"å™ªå£°={current_noise:.3f}" +
              (f" | è§¦å‘æ­¥æ•°={trigger_step}" if trigger_step else "") +
              (f" | å·²æ‰§è¡Œ" if executed else ""))

        # å°†è¦†ç›–ç‡è®°å½•åˆ° TensorBoard
        writer.add_scalar('Performance/Coverage_Rate', final_coverage_rate, episode)
        writer.add_scalar('Performance/Episode_Reward', episode_reward, episode)
        writer.add_scalar('Performance/Max_Coverage_Rate', max_coverage_rate, episode)
        writer.add_scalar('Training/Noise_Std', current_noise, episode)
        writer.add_scalar('Training/Active_UAVs', len(env.active_agents), episode)

        # è®°å½•ç»Ÿè®¡ä¿¡æ¯
        episode_rewards.append(episode_reward)
        episode_coverages.append(final_coverage_rate)

        # ä¿å­˜è§†é¢‘ - ç®€åŒ–æ–¹å¼ (å‚è€ƒåŠ¨æ€ç¯å¢ƒ)
        if record_video and frames:
            video_path = f"{video_dir}/episode_{episode}.mp4"
            with imageio.get_writer(video_path, fps=60) as video:
                for frame in frames:
                    video.append_data(frame)
            print(f"è§†é¢‘å·²ä¿å­˜åˆ° {video_path}")

        # å®šæœŸä¿å­˜æ¨¡å‹
        if episode % 500 == 0:
            model_save_path = f"{model_dir}/matd3_episode_{episode}.pth"
            matd3.save(model_save_path)
            print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {model_save_path}")

        # æ‰“å°ç»Ÿè®¡æ‘˜è¦ï¼ˆæ¯100ä¸ªepisodeï¼‰
        if episode % 100 == 0 and episode > 0:
            avg_reward = np.mean(episode_rewards[-100:]) if len(episode_rewards) >= 100 else np.mean(episode_rewards)
            avg_coverage = np.mean(episode_coverages[-100:]) if len(episode_coverages) >= 100 else np.mean(episode_coverages)
            print(f"\nğŸ“Š Episode {episode} ç»Ÿè®¡æ‘˜è¦:")
            print(f"   æœ€è¿‘100ä¸ªepisodeså¹³å‡å¥–åŠ±: {avg_reward:.2f}")
            print(f"   æœ€è¿‘100ä¸ªepisodeså¹³å‡è¦†ç›–ç‡: {avg_coverage:.3f}")
            print(f"   å½“å‰æœ€å¤§è¦†ç›–ç‡: {max_coverage_rate:.3f}")
            print(f"   å½“å‰å™ªå£°æ°´å¹³: {current_noise:.3f}")
            print("-" * 80)

    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_model_path = f"{model_dir}/matd3_final.pth"
    matd3.save(final_model_path)
    print(f"ğŸ‰ è®­ç»ƒå®Œæˆï¼æœ€ç»ˆæ¨¡å‹ä¿å­˜è‡³: {final_model_path}")

    # å…³é—­ç¯å¢ƒå’Œè®°å½•å™¨
    env.close()
    writer.close()





if __name__ == '__main__':
    main()
