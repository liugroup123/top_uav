# -*- coding: utf-8 -*-
"""
ç®€åŒ–ç¯å¢ƒçš„æµ‹è¯•è„šæœ¬
æµ‹è¯•è®­ç»ƒå¥½çš„MATD3æ¨¡å‹åœ¨ç®€åŒ–ç¯å¢ƒä¸­çš„æ€§èƒ½
"""

import sys
import os

# è·å–å½“å‰æ–‡ä»¶çš„çˆ¶ç›®å½•ï¼ˆmpe_uavç›®å½•ï¼‰
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)  # mpe_uavç›®å½•
sys.path.append(parent_dir)

import cv2
import torch
import numpy as np
from tqdm import tqdm
import time

# å¯¼å…¥ç®€åŒ–ç¯å¢ƒå’ŒMATD3
import importlib.util
uav_env_path = os.path.join(parent_dir, 'uav_top_env', 'uav_env_clean.py')
spec = importlib.util.spec_from_file_location("uav_env_clean", uav_env_path)
uav_env_module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(uav_env_module)
UAVEnv = uav_env_module.UAVEnv

from matd3_no_gat import MATD3

# è·å–å½“å‰æ–‡ä»¶ç›®å½•è·¯å¾„
model_dir = os.path.join(current_dir, './output_clean_env/models/test1')  # æ¨¡å‹æ–‡ä»¶å¤¹
video_dir = os.path.join(current_dir, './test_videos')  # æµ‹è¯•è§†é¢‘ä¿å­˜æ–‡ä»¶å¤¹

# åˆ›å»ºç›®å½•
os.makedirs(video_dir, exist_ok=True)

def test_model(model_path, num_test_episodes=10, render=True, save_video=True):
    """æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print(f"ğŸ§ª å¼€å§‹æµ‹è¯•æ¨¡å‹: {model_path}")
    
    # åˆ›å»ºæµ‹è¯•ç¯å¢ƒ
    env = UAVEnv(
        render_mode='rgb_array' if save_video else ('human' if render else None),
        experiment_type='probabilistic',  # æµ‹è¯•æ¦‚ç‡é©±åŠ¨æ¨¡å¼
        num_agents=6,
        num_targets=10,
        max_steps=200,
        min_active_agents=3,
        max_active_agents=6
    )
    
    print(f"âœ… æµ‹è¯•ç¯å¢ƒåˆ›å»ºæˆåŠŸ")
    print(f"å®éªŒæ¨¡å¼: {env.experiment_type}")
    
    # è·å–ç¯å¢ƒä¿¡æ¯
    obs, _ = env.reset()
    agents = env.agents
    
    obs_dim = env.get_observation_space(agents[0]).shape[0]
    action_dim = env.get_action_space(agents[0]).shape[0]
    
    # åˆ›å»ºMATD3ç®—æ³•
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    obs_dims = {agent: obs_dim for agent in agents}
    action_dims = {agent: action_dim for agent in agents}
    
    matd3 = MATD3(
        agents=agents,
        obs_dims=obs_dims,
        action_dims=action_dims,
        device=device
    )
    
    # åŠ è½½æ¨¡å‹
    try:
        matd3.load(model_path)
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    # æµ‹è¯•ç»Ÿè®¡
    test_results = {
        'episode_rewards': [],
        'episode_coverages': [],
        'episode_types': [],
        'topology_changes': [],
        'final_uav_counts': []
    }
    
    print(f"ğŸ¯ å¼€å§‹æµ‹è¯• ({num_test_episodes} episodes)...")
    
    for episode in tqdm(range(num_test_episodes), desc="æµ‹è¯•è¿›åº¦"):
        obs, _ = env.reset()
        episode_reward = 0
        episode_coverage_history = []
        
        # è®°å½•episodeä¿¡æ¯
        episode_type = env.episode_plan['type']
        trigger_step = env.episode_plan['trigger_step']
        initial_uav_count = len(env.active_agents)
        
        # è§†é¢‘å½•åˆ¶
        frames = []
        record_video = save_video and (episode < 3)  # åªå½•åˆ¶å‰3ä¸ªepisode
        
        print(f"\nEpisode {episode+1}: ç±»å‹={episode_type}" + 
              (f", è§¦å‘æ­¥æ•°={trigger_step}" if trigger_step else ""))
        
        topology_changed = False
        change_step = None
        
        for step in range(env.max_steps):
            # ä½¿ç”¨è®­ç»ƒå¥½çš„ç­–ç•¥é€‰æ‹©åŠ¨ä½œï¼ˆæ— å™ªå£°ï¼‰
            actions = matd3.select_action(obs, noise=0.0)
            
            # è®°å½•å˜åŒ–å‰çš„UAVæ•°é‡
            prev_uav_count = len(env.active_agents)
            
            # æ‰§è¡ŒåŠ¨ä½œ
            next_obs, rewards, dones, truncated, infos = env.step(actions)
            episode_reward += sum(rewards.values())
            
            # æ£€æŸ¥æ‹“æ‰‘å˜åŒ–
            current_uav_count = len(env.active_agents)
            if current_uav_count != prev_uav_count:
                topology_changed = True
                change_step = step + 1
                change_type = "æŸå¤±" if current_uav_count < prev_uav_count else "æ·»åŠ "
                print(f"  ç¬¬{step+1}æ­¥: {change_type} UAV ({prev_uav_count} â†’ {current_uav_count})")
            
            # è®¡ç®—è¦†ç›–ç‡
            coverage_rate, _, _, _ = env.calculate_coverage_complete()
            episode_coverage_history.append(coverage_rate)
            
            obs = next_obs
            
            # å½•åˆ¶è§†é¢‘å¸§
            if record_video:
                frame = env.render(mode='rgb_array')
                if frame is not None:
                    frames.append(frame)
            elif render and not save_video:
                env.render(mode='human')
                time.sleep(0.05)  # æ§åˆ¶æ¸²æŸ“é€Ÿåº¦
        
        # è®°å½•episodeç»“æœ
        final_coverage = np.mean(episode_coverage_history[-10:]) if episode_coverage_history else 0.0
        final_uav_count = len(env.active_agents)
        
        test_results['episode_rewards'].append(episode_reward)
        test_results['episode_coverages'].append(final_coverage)
        test_results['episode_types'].append(episode_type)
        test_results['topology_changes'].append(topology_changed)
        test_results['final_uav_counts'].append(final_uav_count)
        
        print(f"  ç»“æœ: å¥–åŠ±={episode_reward:.2f}, è¦†ç›–ç‡={final_coverage:.3f}, æœ€ç»ˆUAV={final_uav_count}")
        
        # ä¿å­˜è§†é¢‘
        if record_video and frames:
            video_path = f"{video_dir}/test_episode_{episode+1}_{episode_type}.mp4"
            save_video_file(frames, video_path)
            print(f"  ğŸ“¹ è§†é¢‘å·²ä¿å­˜: {video_path}")
    
    # åˆ†ææµ‹è¯•ç»“æœ
    analyze_results(test_results)
    
    env.close()

def analyze_results(results):
    """åˆ†ææµ‹è¯•ç»“æœ"""
    print("\n" + "="*60)
    print("ğŸ“Š æµ‹è¯•ç»“æœåˆ†æ")
    print("="*60)
    
    # åŸºç¡€ç»Ÿè®¡
    avg_reward = np.mean(results['episode_rewards'])
    std_reward = np.std(results['episode_rewards'])
    avg_coverage = np.mean(results['episode_coverages'])
    std_coverage = np.std(results['episode_coverages'])
    
    print(f"å¹³å‡å¥–åŠ±: {avg_reward:.2f} Â± {std_reward:.2f}")
    print(f"å¹³å‡è¦†ç›–ç‡: {avg_coverage:.3f} Â± {std_coverage:.3f}")
    
    # Episodeç±»å‹åˆ†æ
    episode_types = results['episode_types']
    normal_count = episode_types.count('normal')
    loss_count = episode_types.count('loss')
    addition_count = episode_types.count('addition')
    
    print(f"\nEpisodeç±»å‹åˆ†å¸ƒ:")
    print(f"  æ­£å¸¸: {normal_count} ({normal_count/len(episode_types)*100:.1f}%)")
    print(f"  æŸå¤±: {loss_count} ({loss_count/len(episode_types)*100:.1f}%)")
    print(f"  æ·»åŠ : {addition_count} ({addition_count/len(episode_types)*100:.1f}%)")
    
    # æ‹“æ‰‘å˜åŒ–åˆ†æ
    topology_changes = results['topology_changes']
    change_count = sum(topology_changes)
    print(f"\næ‹“æ‰‘å˜åŒ–æ‰§è¡Œ:")
    print(f"  è®¡åˆ’å˜åŒ–: {loss_count + addition_count}")
    print(f"  å®é™…å˜åŒ–: {change_count}")
    print(f"  æ‰§è¡ŒæˆåŠŸç‡: {change_count/(loss_count + addition_count)*100:.1f}%" if (loss_count + addition_count) > 0 else "  æ‰§è¡ŒæˆåŠŸç‡: N/A")
    
    # UAVæ•°é‡åˆ†æ
    final_uav_counts = results['final_uav_counts']
    min_uavs = min(final_uav_counts)
    max_uavs = max(final_uav_counts)
    avg_uavs = np.mean(final_uav_counts)
    
    print(f"\nUAVæ•°é‡ç»Ÿè®¡:")
    print(f"  æœ€å°‘: {min_uavs}")
    print(f"  æœ€å¤š: {max_uavs}")
    print(f"  å¹³å‡: {avg_uavs:.1f}")
    
    # æ€§èƒ½å¯¹æ¯”
    normal_rewards = [results['episode_rewards'][i] for i, t in enumerate(episode_types) if t == 'normal']
    change_rewards = [results['episode_rewards'][i] for i, t in enumerate(episode_types) if t != 'normal']
    
    if normal_rewards and change_rewards:
        print(f"\næ€§èƒ½å¯¹æ¯”:")
        print(f"  æ­£å¸¸episodeå¹³å‡å¥–åŠ±: {np.mean(normal_rewards):.2f}")
        print(f"  å˜åŒ–episodeå¹³å‡å¥–åŠ±: {np.mean(change_rewards):.2f}")
        print(f"  æ€§èƒ½å·®å¼‚: {np.mean(change_rewards) - np.mean(normal_rewards):.2f}")

def save_video_file(frames, path, fps=30):
    """ä¿å­˜è§†é¢‘æ–‡ä»¶"""
    if not frames:
        return
    
    height, width, _ = frames[0].shape
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(path, fourcc, fps, (width, height))
    
    for frame in frames:
        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
        out.write(frame_bgr)
    
    out.release()

def test_random_policy():
    """æµ‹è¯•éšæœºç­–ç•¥ä½œä¸ºåŸºçº¿"""
    print("\nğŸ² æµ‹è¯•éšæœºç­–ç•¥åŸºçº¿...")
    
    env = UAVEnv(
        render_mode=None,
        experiment_type='probabilistic',
        num_agents=6,
        num_targets=10,
        max_steps=200
    )
    
    random_rewards = []
    random_coverages = []
    
    for episode in range(10):
        obs, _ = env.reset()
        episode_reward = 0
        
        for step in range(env.max_steps):
            # éšæœºåŠ¨ä½œ
            actions = {agent: env.get_action_space(agent).sample() for agent in env.agents}
            obs, rewards, dones, _, _ = env.step(actions)
            episode_reward += sum(rewards.values())
        
        coverage_rate, _, _, _ = env.calculate_coverage_complete()
        random_rewards.append(episode_reward)
        random_coverages.append(coverage_rate)
    
    print(f"éšæœºç­–ç•¥ - å¹³å‡å¥–åŠ±: {np.mean(random_rewards):.2f}, å¹³å‡è¦†ç›–ç‡: {np.mean(random_coverages):.3f}")
    env.close()

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•ç®€åŒ–ç¯å¢ƒä¸­çš„è®­ç»ƒæ¨¡å‹")

    # æ¨¡å‹è·¯å¾„
    model_path = f"{model_dir}/matd3_final.pth"

    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print("è¯·å…ˆè¿è¡Œ main_clean_env.py è¿›è¡Œè®­ç»ƒ")
        print(f"ğŸ“ æœŸæœ›æ¨¡å‹è·¯å¾„: {model_path}")
        return
    
    # æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹
    test_model(
        model_path=model_path,
        num_test_episodes=20,
        render=False,  # è®¾ç½®ä¸ºTrueå¯ä»¥çœ‹åˆ°å®æ—¶æ¸²æŸ“
        save_video=True
    )
    
    # æµ‹è¯•éšæœºç­–ç•¥åŸºçº¿
    test_random_policy()
    
    print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")

if __name__ == '__main__':
    main()
