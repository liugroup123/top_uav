#!/usr/bin/env python3
"""
æµ‹è¯•MATD3æ˜¯å¦èƒ½æ­£å¸¸è®­ç»ƒæ‹“æ‰‘UAVç¯å¢ƒ
"""

import sys
import os
import torch
import numpy as np

# æ·»åŠ è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

# å¯¼å…¥æ¨¡å—
from uav_top_env.uav_env_top import UAVEnv
from matd3_no_gat import MATD3, ReplayBuffer
from config import CONFIG

def test_environment_compatibility():
    """æµ‹è¯•ç¯å¢ƒå…¼å®¹æ€§"""
    print("=== æµ‹è¯•ç¯å¢ƒå…¼å®¹æ€§ ===")
    
    try:
        # æµ‹è¯•ä¸åŒå®éªŒç±»å‹
        experiment_types = ['normal', 'uav_loss', 'uav_addition', 'random_mixed']
        
        for exp_type in experiment_types:
            print(f"\næµ‹è¯•å®éªŒç±»å‹: {exp_type}")
            
            # åˆ›å»ºç¯å¢ƒ
            env = UAVEnv(
                render_mode=None,
                experiment_type=exp_type,
                num_agents=6,
                num_targets=10
            )
            
            # é‡ç½®ç¯å¢ƒ
            obs, _ = env.reset()
            agents = env.agents
            
            print(f"  âœ“ ç¯å¢ƒåˆ›å»ºæˆåŠŸ")
            print(f"  âœ“ æ™ºèƒ½ä½“æ•°é‡: {len(agents)}")
            print(f"  âœ“ è§‚å¯Ÿç©ºé—´ç»´åº¦: {env.get_observation_space(agents[0]).shape}")
            print(f"  âœ“ åŠ¨ä½œç©ºé—´ç»´åº¦: {env.get_action_space(agents[0]).shape}")
            print(f"  âœ“ åˆå§‹æ´»è·ƒUAV: {len(env.active_agents)}")
            
            # è¿è¡Œå‡ æ­¥
            for step in range(5):
                actions = {agent: env.get_action_space(agent).sample() for agent in agents}
                obs, rewards, dones, _, _ = env.step(actions)
                
                if step == 0:
                    print(f"  âœ“ ç¬¬ä¸€æ­¥æ‰§è¡ŒæˆåŠŸ")
                    print(f"  âœ“ å¥–åŠ±æ•°é‡: {len(rewards)}")
                    print(f"  âœ“ è§‚å¯Ÿæ•°é‡: {len(obs)}")
            
            print(f"  âœ“ æœ€ç»ˆæ´»è·ƒUAV: {len(env.active_agents)}")
            env.close()
            
        return True
        
    except Exception as e:
        print(f"  âœ— ç¯å¢ƒæµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def test_matd3_compatibility():
    """æµ‹è¯•MATD3å…¼å®¹æ€§"""
    print("\n=== æµ‹è¯•MATD3å…¼å®¹æ€§ ===")
    
    try:
        # åˆ›å»ºç¯å¢ƒ
        env = UAVEnv(
            render_mode=None,
            experiment_type='uav_loss',
            num_agents=5,
            num_targets=8
        )
        
        obs, _ = env.reset()
        agents = env.agents
        
        # è·å–è§‚æµ‹å’ŒåŠ¨ä½œç©ºé—´ç»´åº¦
        obs_dim = env.get_observation_space(agents[0]).shape[0]
        action_dim = env.get_action_space(agents[0]).shape[0]
        
        print(f"  è§‚å¯Ÿç»´åº¦: {obs_dim}")
        print(f"  åŠ¨ä½œç»´åº¦: {action_dim}")
        
        # åˆ›å»ºè§‚æµ‹å’ŒåŠ¨ä½œç»´åº¦çš„å­—å…¸
        obs_dims = {agent: obs_dim for agent in agents}
        action_dims = {agent: action_dim for agent in agents}
        
        # åˆå§‹åŒ– MATD3
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        matd3 = MATD3(
            agents=agents,
            obs_dims=obs_dims,
            action_dims=action_dims,
            device=device,
            actor_lr=1e-4,
            critic_lr=1e-3
        )
        
        print(f"  âœ“ MATD3åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•åŠ¨ä½œé€‰æ‹©
        actions = matd3.select_action(obs, noise=0.1)
        print(f"  âœ“ åŠ¨ä½œé€‰æ‹©æˆåŠŸï¼ŒåŠ¨ä½œæ•°é‡: {len(actions)}")
        
        # æµ‹è¯•ç¯å¢ƒæ­¥è¿›
        next_obs, rewards, dones, _, _ = env.step(actions)
        print(f"  âœ“ ç¯å¢ƒæ­¥è¿›æˆåŠŸ")
        
        # æµ‹è¯•ç»éªŒå›æ”¾
        replay_buffer = ReplayBuffer(
            buffer_size=1000,
            batch_size=32,
            device=device
        )
        
        # æ·»åŠ ç»éªŒ
        all_agents = set(agents)
        obs_filled = {agent: obs.get(agent, np.zeros(obs_dim)) for agent in all_agents}
        actions_filled = {agent: actions.get(agent, np.zeros(action_dim)) for agent in all_agents}
        rewards_filled = {agent: rewards.get(agent, 0.0) for agent in all_agents}
        next_obs_filled = {agent: next_obs.get(agent, np.zeros(obs_dim)) for agent in all_agents}
        dones_filled = {agent: dones.get(agent, True) for agent in all_agents}
        
        replay_buffer.add(obs_filled, actions_filled, rewards_filled, next_obs_filled, dones_filled)
        print(f"  âœ“ ç»éªŒæ·»åŠ æˆåŠŸ")
        
        env.close()
        return True
        
    except Exception as e:
        print(f"  âœ— MATD3æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def test_topology_changes():
    """æµ‹è¯•æ‹“æ‰‘å˜åŒ–"""
    print("\n=== æµ‹è¯•æ‹“æ‰‘å˜åŒ– ===")
    
    try:
        env = UAVEnv(
            render_mode=None,
            experiment_type='random_mixed',
            num_agents=6,
            num_targets=8,
            topology_change_probability=0.1  # é«˜æ¦‚ç‡ä¾¿äºæµ‹è¯•
        )
        
        obs, _ = env.reset()
        initial_active = len(env.active_agents)
        print(f"  åˆå§‹æ´»è·ƒUAV: {initial_active}")
        
        topology_changes = 0
        for step in range(50):
            actions = {agent: env.get_action_space(agent).sample() for agent in env.agents}
            
            prev_active = len(env.active_agents)
            obs, rewards, dones, _, _ = env.step(actions)
            current_active = len(env.active_agents)
            
            if current_active != prev_active:
                topology_changes += 1
                change_type = "å¤±æ•ˆ" if current_active < prev_active else "æ·»åŠ "
                print(f"    Step {step}: {change_type} - UAVæ•°é‡ {prev_active} -> {current_active}")
        
        print(f"  âœ“ 50æ­¥å†…å‘ç”Ÿ {topology_changes} æ¬¡æ‹“æ‰‘å˜åŒ–")
        print(f"  âœ“ æœ€ç»ˆæ´»è·ƒUAV: {len(env.active_agents)}")
        
        env.close()
        return True
        
    except Exception as e:
        print(f"  âœ— æ‹“æ‰‘å˜åŒ–æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def test_training_loop():
    """æµ‹è¯•ç®€åŒ–çš„è®­ç»ƒå¾ªç¯"""
    print("\n=== æµ‹è¯•è®­ç»ƒå¾ªç¯ ===")
    
    try:
        env = UAVEnv(
            render_mode=None,
            experiment_type='uav_loss',
            num_agents=5,
            num_targets=8
        )
        
        obs, _ = env.reset()
        agents = env.agents
        
        # è·å–ç»´åº¦
        obs_dim = env.get_observation_space(agents[0]).shape[0]
        action_dim = env.get_action_space(agents[0]).shape[0]
        obs_dims = {agent: obs_dim for agent in agents}
        action_dims = {agent: action_dim for agent in agents}
        
        # åˆ›å»ºMATD3
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        matd3 = MATD3(
            agents=agents,
            obs_dims=obs_dims,
            action_dims=action_dims,
            device=device
        )
        
        # åˆ›å»ºç»éªŒå›æ”¾
        replay_buffer = ReplayBuffer(buffer_size=1000, batch_size=32, device=device)
        
        # ç®€åŒ–è®­ç»ƒå¾ªç¯
        total_reward = 0
        for episode in range(3):  # åªæµ‹è¯•3ä¸ªepisode
            obs, _ = env.reset()
            episode_reward = 0
            
            for step in range(20):  # æ¯ä¸ªepisodeåªè¿è¡Œ20æ­¥
                # é€‰æ‹©åŠ¨ä½œ
                actions = matd3.select_action(obs, noise=0.1)
                
                # ç¯å¢ƒæ­¥è¿›
                next_obs, rewards, dones, _, _ = env.step(actions)
                episode_reward += sum(rewards.values())
                
                # æ·»åŠ ç»éªŒ
                all_agents = set(agents)
                obs_filled = {agent: obs.get(agent, np.zeros(obs_dim)) for agent in all_agents}
                actions_filled = {agent: actions.get(agent, np.zeros(action_dim)) for agent in all_agents}
                rewards_filled = {agent: rewards.get(agent, 0.0) for agent in all_agents}
                next_obs_filled = {agent: next_obs.get(agent, np.zeros(obs_dim)) for agent in all_agents}
                dones_filled = {agent: dones.get(agent, True) for agent in all_agents}
                
                replay_buffer.add(obs_filled, actions_filled, rewards_filled, next_obs_filled, dones_filled)
                
                # è®­ç»ƒï¼ˆå¦‚æœæœ‰è¶³å¤Ÿç»éªŒï¼‰
                if len(replay_buffer) > 32:
                    loss_info = matd3.train(replay_buffer)
                    if episode == 0 and step == 0:
                        print(f"    é¦–æ¬¡è®­ç»ƒæˆåŠŸï¼ŒActoræŸå¤±: {loss_info['actor_loss']:.4f}")
                
                obs = next_obs
            
            total_reward += episode_reward
            print(f"  Episode {episode + 1}: å¥–åŠ± = {episode_reward:.2f}, æ´»è·ƒUAV = {len(env.active_agents)}")
        
        print(f"  âœ“ è®­ç»ƒå¾ªç¯æµ‹è¯•å®Œæˆï¼Œå¹³å‡å¥–åŠ±: {total_reward/3:.2f}")
        
        env.close()
        return True
        
    except Exception as e:
        print(f"  âœ— è®­ç»ƒå¾ªç¯æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ” å¼€å§‹æµ‹è¯•MATD3ä¸æ‹“æ‰‘UAVç¯å¢ƒçš„å…¼å®¹æ€§...\n")
    
    tests = [
        ("ç¯å¢ƒå…¼å®¹æ€§", test_environment_compatibility),
        ("MATD3å…¼å®¹æ€§", test_matd3_compatibility),
        ("æ‹“æ‰‘å˜åŒ–", test_topology_changes),
        ("è®­ç»ƒå¾ªç¯", test_training_loop)
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        try:
            result = test_func()
            results[test_name] = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        except Exception as e:
            results[test_name] = f"âŒ é”™è¯¯: {str(e)}"
    
    print("\n" + "="*50)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    print("="*50)
    
    for test_name, result in results.items():
        print(f"{test_name}: {result}")
    
    # æ€»ç»“
    passed_tests = sum(1 for result in results.values() if "âœ…" in result)
    total_tests = len(results)
    
    print(f"\né€šè¿‡æµ‹è¯•: {passed_tests}/{total_tests}")
    
    if passed_tests == total_tests:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼MATD3å¯ä»¥æ­£å¸¸è®­ç»ƒæ‹“æ‰‘UAVç¯å¢ƒã€‚")
        print("\nğŸ“ å»ºè®®:")
        print("- å¯ä»¥ç›´æ¥è¿è¡Œ main_no_gat.py å¼€å§‹è®­ç»ƒ")
        print("- å¯ä»¥åœ¨ç¯å¢ƒåˆå§‹åŒ–æ—¶ä¿®æ”¹ experiment_type æ¥æµ‹è¯•ä¸åŒçš„æ‹“æ‰‘å˜åŒ–")
        print("- å»ºè®®å…ˆç”¨ 'normal' æ¨¡å¼è®­ç»ƒåŸºç¡€ç­–ç•¥ï¼Œå†ç”¨å…¶ä»–æ¨¡å¼è®­ç»ƒ")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚")

if __name__ == '__main__':
    main()
