#!/usr/bin/env python3
"""
æµ‹è¯•GATè®­ç»ƒç‰ˆæœ¬ä¸éGATç‰ˆæœ¬çš„å¯¹æ¯”
"""

import sys
import os

# æ·»åŠ è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

import torch
import numpy as np

def test_gat_training_setup():
    """æµ‹è¯•GATè®­ç»ƒè®¾ç½®"""
    print("ğŸ” æµ‹è¯•GATè®­ç»ƒè®¾ç½®...\n")
    
    try:
        from uav_top_env.uav_env_top import UAVEnv
        from matd3_no_gat import MATD3, ReplayBuffer
        from config import CONFIG
        
        # åˆ›å»ºç¯å¢ƒ
        env = UAVEnv(
            render_mode=None,
            experiment_type='uav_loss',
            num_agents=6,
            num_targets=10
        )
        
        print("=== æµ‹è¯•GATè®­ç»ƒæ¨¡å¼ ===")
        
        # æµ‹è¯•GATè®­ç»ƒæ¨¡å¼
        env.training = True
        print(f"âœ… GATè®­ç»ƒæ¨¡å¼å·²å¯ç”¨: {env.training}")
        
        # è·å–GATå‚æ•°
        gat_params = list(env.get_gat_parameters())
        gat_param_count = sum(p.numel() for p in gat_params)
        print(f"âœ… GATå‚æ•°æ•°é‡: {gat_param_count}")
        
        # æµ‹è¯•ç¯å¢ƒé‡ç½®å’Œè§‚å¯Ÿ
        obs, _ = env.reset()
        agents = env.agents
        
        obs_dim = env.get_observation_space(agents[0]).shape[0]
        action_dim = env.get_action_space(agents[0]).shape[0]
        
        print(f"âœ… è§‚å¯Ÿç»´åº¦: {obs_dim}")
        print(f"âœ… åŠ¨ä½œç»´åº¦: {action_dim}")
        print(f"âœ… æ™ºèƒ½ä½“æ•°é‡: {len(agents)}")
        
        # åˆ›å»ºMATD3
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        obs_dims = {agent: obs_dim for agent in agents}
        action_dims = {agent: action_dim for agent in agents}
        
        matd3 = MATD3(
            agents=agents,
            obs_dims=obs_dims,
            action_dims=action_dims,
            device=device,
            actor_lr=1e-4,
            critic_lr=1e-3
        )
        
        print(f"âœ… MATD3åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•ä¼˜åŒ–å™¨é‡æ–°é…ç½®
        print("\n=== æµ‹è¯•ä¼˜åŒ–å™¨é…ç½® ===")
        
        original_actor_params = sum(p.numel() for p in matd3.actors[agents[0]].parameters())
        original_critic_params = sum(p.numel() for p in matd3.critics_1[agents[0]].parameters()) + sum(p.numel() for p in matd3.critics_2[agents[0]].parameters())
        
        print(f"åŸå§‹Actorå‚æ•°: {original_actor_params}")
        print(f"åŸå§‹Criticå‚æ•°: {original_critic_params}")
        print(f"GATå‚æ•°: {gat_param_count}")
        
        # é‡æ–°é…ç½®ä¼˜åŒ–å™¨
        for agent in agents:
            actor_params = list(matd3.actors[agent].parameters())
            critic_params = list(matd3.critics_1[agent].parameters()) + list(matd3.critics_2[agent].parameters())
            
            # é‡æ–°åˆ›å»ºä¼˜åŒ–å™¨ï¼ŒåŒ…å«GATå‚æ•°
            matd3.actor_optimizers[agent] = torch.optim.Adam(
                actor_params + gat_params, 
                lr=1e-4
            )
            matd3.critic_optimizers[agent] = torch.optim.Adam(
                critic_params + gat_params, 
                lr=1e-3
            )
        
        print("âœ… ä¼˜åŒ–å™¨é‡æ–°é…ç½®å®Œæˆ")
        
        # æµ‹è¯•è®­ç»ƒæ­¥éª¤
        print("\n=== æµ‹è¯•è®­ç»ƒæ­¥éª¤ ===")
        
        # åˆ›å»ºç»éªŒå›æ”¾
        replay_buffer = ReplayBuffer(buffer_size=1000, batch_size=32, device=device)
        
        # æ”¶é›†ä¸€äº›ç»éªŒ
        for step in range(50):
            actions = matd3.select_action(obs, noise=0.1)
            next_obs, rewards, dones, _, _ = env.step(actions)
            
            all_agents = set(agents)
            obs_filled = {agent: obs.get(agent, np.zeros(obs_dim)) for agent in all_agents}
            actions_filled = {agent: actions.get(agent, np.zeros(action_dim)) for agent in all_agents}
            rewards_filled = {agent: rewards.get(agent, 0.0) for agent in all_agents}
            next_obs_filled = {agent: next_obs.get(agent, np.zeros(obs_dim)) for agent in all_agents}
            dones_filled = {agent: dones.get(agent, True) for agent in all_agents}
            
            replay_buffer.add(obs_filled, actions_filled, rewards_filled, next_obs_filled, dones_filled)
            obs = next_obs
        
        print(f"âœ… æ”¶é›†äº† {len(replay_buffer)} ä¸ªç»éªŒ")
        
        # æµ‹è¯•è®­ç»ƒ
        if len(replay_buffer) > 32:
            loss_info = matd3.train(replay_buffer)
            print(f"âœ… è®­ç»ƒæˆåŠŸï¼ActoræŸå¤±: {loss_info['actor_loss']:.4f}, CriticæŸå¤±: {loss_info['critic_loss']:.4f}")
            print("ğŸ”¥ GATå‚æ•°å·²ä¸ç­–ç•¥ç½‘ç»œè”åˆæ›´æ–°")
        
        env.close()
        
        print("\n=== å¯¹æ¯”æ€»ç»“ ===")
        print("main_no_gat.py:")
        print("  - GATä½œä¸ºå›ºå®šç‰¹å¾æå–å™¨")
        print("  - åªè®­ç»ƒç­–ç•¥ç½‘ç»œå‚æ•°")
        print("  - è®­ç»ƒç¨³å®šï¼Œæ”¶æ•›å¿«")
        print("  - GATç‰¹å¾è¢«detach()åˆ‡æ–­æ¢¯åº¦")
        
        print("\nmain_with_gat.py:")
        print("  - GATä¸ç­–ç•¥ç½‘ç»œè”åˆè®­ç»ƒ")
        print("  - ç«¯åˆ°ç«¯æ¢¯åº¦ä¼ æ’­")
        print("  - ç†è®ºæ€§èƒ½æ›´é«˜ï¼Œä½†è®­ç»ƒå¤æ‚")
        print("  - GATå‚æ•°åŒ…å«åœ¨ä¼˜åŒ–å™¨ä¸­")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ” å¼€å§‹æµ‹è¯•GATè®­ç»ƒç‰ˆæœ¬...\n")
    
    result = test_gat_training_setup()
    
    if result:
        print("\nğŸ‰ GATè®­ç»ƒç‰ˆæœ¬æµ‹è¯•é€šè¿‡ï¼")
        print("\nğŸ“ ä½¿ç”¨å»ºè®®:")
        print("1. å…ˆç”¨ main_no_gat.py è®­ç»ƒåŸºç¡€ç­–ç•¥")
        print("2. å†ç”¨ main_with_gat.py è¿›è¡Œç«¯åˆ°ç«¯è®­ç»ƒ")
        print("3. å¯¹æ¯”ä¸¤ç§æ–¹æ³•çš„æ€§èƒ½å·®å¼‚")
        print("4. GATè®­ç»ƒç‰ˆæœ¬å¯èƒ½éœ€è¦æ›´å°çš„å­¦ä¹ ç‡")
    else:
        print("\nâŒ GATè®­ç»ƒç‰ˆæœ¬æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç ã€‚")

if __name__ == '__main__':
    main()
